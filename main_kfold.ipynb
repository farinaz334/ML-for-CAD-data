{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAD\n",
    "This data set is taken from [here](https://ieee-dataport.org/open-access/heart-disease-dataset-comprehensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier,RandomForestClassifier,VotingClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate different performance metric for the model clf\n",
    "def clf_score(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ac = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    pr = precision_score(y_test,y_pred)\n",
    "    re  = recall_score(y_test,y_pred)\n",
    "   \n",
    "    return [ac,f1,pr,re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalsie the input base on the norm parametrs, if norm is none, no normalisation will happen\n",
    "def normalisation(X_train,X_test, norm ):\n",
    "    if norm != None:\n",
    "        scaler1 = norm\n",
    "        \n",
    "        X_train  =  scaler1.fit_transform(X_train)\n",
    "        X_test  =  scaler1.transform(X_test)\n",
    "\n",
    "    #X_train =  scaler1.fit_transform(X_train)\n",
    "    #X_test =  scaler1.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for kfold results\n",
    "def show_statics(arr):\n",
    "    \n",
    "    ac = np.mean([ x[0] for x in arr]), np.std([ x[0] for x in arr])\n",
    "    f1 = np.mean([ x[1] for x in arr]), np.std([ x[1] for x in arr])\n",
    "    pr = np.mean([ x[2] for x in arr]), np.std([ x[2] for x in arr])\n",
    "    re = np.mean([ x[3] for x in arr]), np.std([ x[3] for x in arr])\n",
    "    return [ac,f1,pr,re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model and \n",
    "def train_clf(clf, X,y,norm,  print_ind = True):\n",
    "    Accs = []\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(X)):\n",
    "            \n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_valid = X[valid_index]\n",
    "        y_valid = y[valid_index]\n",
    "        X_train , X_valid = normalisation(X_train , X_valid,norm)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        res = clf_score(clf,X_train,y_train)\n",
    "        if (print_ind): print('Train: ', res)\n",
    "\n",
    "        res = clf_score(clf,X_valid,y_valid)\n",
    "        if (print_ind): print('Valid: ', res)\n",
    "        Accs.append(res)\n",
    "    #print(show_statics( Accs))\n",
    "    return show_statics( Accs)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data.csv\")\n",
    "df1 = df1.drop_duplicates()\n",
    "y = df1[\"target\"].to_numpy()\n",
    "X = df1.drop(\"target\", axis=1).to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample after removing duplicates: N 410, P 508\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample after removing duplicates: N %d, P %d\" %(len(y[y==0]),len(y[y==1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=10,  \n",
    "                                   test_size=0.2,  \n",
    "                                   shuffle=True)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle = True)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 98)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test==0]),len(y_test[y_test==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplying Machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm =  StandardScaler()\n",
    "X_train,X_test = normalisation(X_train,X_test, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "StandardScaler() 0.8803221029248427 0.8315217391304348 7 1.4\n"
     ]
    }
   ],
   "source": [
    "n_neigh = [1,2,3,4,5,6,7,8,9,10]\n",
    "ps = [1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2]\n",
    "\n",
    "best_valid = 0\n",
    "best_test = 0\n",
    "best_n = 0\n",
    "best_p = 0\n",
    "for n in n_neigh:\n",
    "    for p in ps:\n",
    "        #print('------',norm, n , p)\n",
    "        clf_knn_org = KNeighborsClassifier(n_neighbors=n,p = p )\n",
    "        ac,f1,pr,re = train_clf(clf_knn_org,X_train,y_train,norm,False)\n",
    "        #print('Valid :')\n",
    "        #print(ac,f1,pr,re)\n",
    "    \n",
    "        #print('Test :')\n",
    "        #print(n , p)\n",
    "        ac_t,f1_t,pr_t,re_t = clf_score( clf_knn_org,X_test, y_test)\n",
    "        if (ac[0] > best_valid):\n",
    "            best_valid = ac[0]\n",
    "            best_test  = ac_t\n",
    "            best_n = n\n",
    "            best_p = p\n",
    "        #print('--------')\n",
    "\n",
    "print('******************')\n",
    "print(norm, best_valid , best_test, best_n,best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "[0.8315217391304348, 0.8410256410256411, 0.845360824742268, 0.8367346938775511]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "clf_knn_org = KNeighborsClassifier(n_neighbors=best_n,p = best_p )\n",
    "x1 , x2 = normalisation(X_train, X_test,StandardScaler())\n",
    "clf_knn_org.fit(x1, y_train)\n",
    "print(norm)\n",
    "print(clf_score( clf_knn_org,x2, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler() 0.8693631988152536 0.8315217391304348 1 0.01 rbf\n"
     ]
    }
   ],
   "source": [
    " \n",
    "Cs = [1,51,101]#,151,201,251]\n",
    "gammas = [0.01,0.1]#,0.2,0.3,0.4]\n",
    "kernels = ['rbf', 'linear']\n",
    "best_valid = 0\n",
    "best_test = 0\n",
    "best_C = 0\n",
    "best_gamma = 0\n",
    "\n",
    "\n",
    "for k in kernels:\n",
    "    for c in Cs:\n",
    "        for g in gammas:\n",
    "        \n",
    "            #print('------',norm, c , g, k)\n",
    "            clf_svm_org = svm.SVC(C=c,gamma=g,kernel=k)\n",
    "            ac,f1,pr,re = train_clf(clf_svm_org,X_train,y_train,None,False)\n",
    "            #print('Valid :')\n",
    "            #print(ac,f1,pr,re)\n",
    "        \n",
    "            #print('Test :')\n",
    "            #print(n , p)\n",
    "            ac_t,f1_t,pr_t,re_t = clf_score( clf_svm_org,X_test, y_test)\n",
    "            if (ac[0] >= best_valid):\n",
    "                best_valid = ac[0]\n",
    "                best_test  = ac_t\n",
    "                best_C = c\n",
    "                best_gamma = g\n",
    "                best_kernel = k\n",
    "            #print('--------')\n",
    "\n",
    "    #print('******************')\n",
    "print(norm, best_valid , best_test, best_C,best_gamma,best_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "[0.842391304347826, 0.8542713567839196, 0.8415841584158416, 0.8673469387755102]\n"
     ]
    }
   ],
   "source": [
    "clf_svm_org =  svm.SVC(C=best_C,gamma=best_gamma,kernel=best_kernel,probability=True)\n",
    "clf_svm_org.fit(X_train, y_train)\n",
    "print(norm)\n",
    "print(clf_score( clf_svm_org,X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler() 0.8312476860422064 0.842391304347826 50 1\n",
      "StandardScaler() 0.8529803776379119 0.842391304347826 50 2\n",
      "StandardScaler() 0.8570899666790078 0.842391304347826 50 3\n",
      "StandardScaler() 0.866604961125509 0.842391304347826 50 4\n",
      "StandardScaler() 0.8694557571269901 0.842391304347826 50 7\n",
      "StandardScaler() 0.8748056275453535 0.842391304347826 50 9\n",
      "StandardScaler() 0.8775268419104034 0.842391304347826 60 9\n"
     ]
    }
   ],
   "source": [
    "ns = np.arange(50,250,10)\n",
    "max_depths = np.arange(1,10,1)\n",
    "min_samples_leaves =  np.arange(1,10,1)\n",
    "best_valid = 0\n",
    "best_test = 0\n",
    "best_n = 0\n",
    "best_max_depth = 0\n",
    "best_min_samples_leaf = 0\n",
    "\n",
    "for n in ns:\n",
    "    for min_samples_leaf in min_samples_leaves:\n",
    "        for max_depth in max_depths:\n",
    "                 \n",
    "                clf_rf_new = RandomForestClassifier(n_estimators=n, min_samples_leaf=min_samples_leaf ,max_depth= max_depth, bootstrap=True ,   random_state=0 )\n",
    "                ac,f1,pr,re = train_clf(clf_rf_new,X_train,y_train,None,False)\n",
    "\n",
    "                ac_t,f1_t,pr_t,re_t = clf_score( clf_svm_org,X_test, y_test)\n",
    "                if (ac[0] >= best_valid):\n",
    "                    best_valid = ac[0]\n",
    "                    best_test  = ac_t\n",
    "                    best_n = n\n",
    "                    best_max_depth = max_depth\n",
    "                    best_min_samples_leaf = min_samples_leaf\n",
    "                    print(norm, best_valid , best_test, best_n,best_max_depth) \n",
    "            #print('--------')\n",
    "\n",
    "print('******************')\n",
    "print(norm, best_valid , best_test, best_n,best_max_depth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "clf_rf_new =  RandomForestClassifier(n_estimators=n,bootstrap=True ,   max_depth= max_depth, min_samples_leaf=best_min_samples_leaf , random_state=0 )\n",
    "\n",
    " \n",
    "clf_rf_new.fit(X_train, y_train)\n",
    "print(norm)\n",
    "print(clf_score( clf_rf_new,X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_tuples1 = [('clf_svm',  clf_svm_org),('clf_knn_org', clf_knn_org), ('clf_rf',clf_rf_new)  ]\n",
    "model_tuples2 = [('clf_svm1',  clf_svm_org),('clf_knn1', clf_knn_org), ('clf_rf1',clf_rf_new)  ]\n",
    "model_tuples3 = [('clf_svm2',  clf_svm_org),('clf_knn2', clf_knn_org), ('clf_rf2',clf_rf_new)  ]\n",
    "\n",
    "best_m1 = None\n",
    "best_m2 = None\n",
    "best_m3 = None  \n",
    "best_valid = 0\n",
    "best_test = 0\n",
    "for m1 in model_tuples1:\n",
    "    for m2 in model_tuples2:\n",
    "        for m3 in model_tuples3:\n",
    "            estimator = [] \n",
    "            estimator.append(m1)\n",
    "            estimator.append(m2)\n",
    "            estimator.append(m3)\n",
    "          \n",
    "            stacked_model = VotingClassifier(estimators = estimator, voting ='soft') \n",
    "           \n",
    "            ac,f1,pr,re = train_clf(stacked_model,X_train,y_train,None,False)\n",
    "\n",
    "            ac_t,f1_t,pr_t,re_t = clf_score( stacked_model,X_test, y_test)\n",
    "            if (ac[0] >= best_valid):\n",
    "                best_valid = ac[0]\n",
    "                best_test  = ac_t\n",
    "                best_m1 = m1\n",
    "                best_m2 = m2\n",
    "                best_m3 = m3\n",
    "                print(best_m1[0], best_m2[0], best_m3[0], best_valid, best_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = []  \n",
    "estimator.append(best_m1)\n",
    "estimator.append(best_m2)\n",
    "estimator.append(best_m3)\n",
    "stacked_model = VotingClassifier(estimators = estimator, voting ='soft') \n",
    " \n",
    "stacked_model.fit(X_train, y_train)\n",
    "print(clf_score( stacked_model,X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackingClassifier(\n",
    "    estimators=[ best_m1,best_m2,best_m3 ],\n",
    "    final_estimator=SVC(C=100,gamma=0.01)\n",
    ")\n",
    " \n",
    "stacked_model.fit(X_train, y_train)\n",
    "#95.04\n",
    " \n",
    "print(clf_score( stacked_model,X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
